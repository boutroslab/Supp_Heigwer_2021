---
title: "classifier_development"
author: "Sergi"
date: "1/13/2020"
output: pdf_document
abstract: in this markdown I will develop a supervised learning algorithm to classify cells into crowded and isolated. In order to do that, first I will manually label a set of single cell images into the corresponding groups. Then I will train and optimise an algorithm to learn this classification. For labelling an image of a big field of view around the cells is available. 
editor_options: 
  chunk_output_type: console
---
#Package loading
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(dbplyr)
library(corrr)
library(caret)
library(umap)
library(randomForest)
library(EBImage)
library(e1071)
library(RColorBrewer)
library(plotly)
library(Rtsne)
library(jsonlite)
library(kernlab)
library(RSQLite)
library(rlist)
library(plyr)
library(LMGene)
library(gridExtra)
library(ggpubr)
library(uwot)
library(kernlab)
library(nnet)
library(SuperLearner)
library(KernelKnn)
library(ranger)
library(ISLR)

query_genes <- readRDS("objects/query_genes.rds") %>% separate(plate_barcode, into = c("barcode", "screen"), sep = "_")

target_genes <- readRDS("objects/target_genes.rds")

filtering_classifier <- readRDS("objects/filtering_classifier.rds")
```
#Training set
I labelled 550 cells. The training set was almost perfectly balanced with almost the same number of crowded and isolated cells (280 and 270 respectively). I did not do reinforced learning during the labelling process. Furthermore, I did not show the model probabilities as I was assigning cells to the groups. 
Despite this, the final accuracy of the model was around 90 %. Similar results were obtained for the time resolved screen. 
```{r}

#The accuracy of the random forest is 90.3 %. 

initial_classifier_rf <- readRDS("objects/classifier.rds")

#As expected the most important features for the model are by far the distance features. Interestingly, the following features in terms of importance are the tubulin and actin quantiles of intensity. 

varImpPlot(initial_classifier_rf)

training_set <- readRDS("training_set_dataframe/training_set.rds") 

#After the adjustment of the filtering classifier (instead of a grid search of mtry, I defined the optimal value for the hyperparameter), 2 cells were 
#wrongly segmented and therefore eliminated from the training set. 

training_set <- training_set %>% filter(predict(filtering_classifier, training_set) == "Yes")

```
##UMAP
We expect the groups to be separated clearly when plot in a UMAP. 
```{r}

load("~/Desktop/Sergi_master_thesis/themes/umap_theme.RData")

google_green <- "#3cba54"

google_red <- "#db3236"

colours <- c(google_red, google_green)

#I will only select the 10 most important features for the initial random forest algorithm. 

imp_features_rf <- initial_classifier_rf$importance %>% as.data.frame() %>% rownames_to_column(var = "feature") %>%
                      arrange(desc(MeanDecreaseAccuracy)) %>% pull(feature) %>% .[1:10]

umap_trn_set_data <- training_set %>% select(imp_features_rf) %>% uwot::umap() %>% as.data.frame() %>% dplyr::rename(dimension1 = V1, dimension2 = V2) %>% 
                  mutate(context = factor(training_set %>% pull(context)))

umap_trn_set_plot <-  ggplot(umap_trn_set_data, aes(x=dimension1, y= dimension2, color = context))+
                                            geom_point(size = 2)+
                                            umap_theme()+
                                            ggtitle(paste0("Training set"))+
                                            theme(
                                            legend.title = element_text(size = 16),
                                            plot.title = element_text(size = 25))+
                                            scale_color_manual(values = colours)+
                                            guides(colour = guide_legend(nrow = 1, byrow = T, override.aes = list(size = 6)))+
                                            xlab("UMAP dimension 1")+
                                            ylab("UMAP dimension 2")+
                                            labs(color = "Local context")

#The separation between the groups is almost perfect. 

ggsave(umap_trn_set_plot, filename = "objects_classification/plots/umap_training_set_imp_features.pdf", height = 7, width = 7)

```
#Model optimisation
Although the initial random forest already shows a high accuracy I will try to optimise the parameteres in order to get an algorithm as precise as possible. I will also train a svm to see if it performs well on the training set as well. 
##Random forest
```{r}

load("objects/numeric_features.RData")

control <- trainControl(method = "cv", number = 5, verboseIter = T, savePredictions = T)

rf_grid <- expand.grid(mtry = c(4:25))

set.seed(100)
rf_optimized <- train(context~., data = training_set %>% select(context, numeric_features) , 
                      trControl = control, method = "rf", tuneGrid = rf_grid, verbose = T)

#The accuracy has increased mildly to 90.8 %. The optimal mtry is 15. 

set.seed(100)
rf_optimized <- train(context~., data = training_set %>% select(context, numeric_features) , trControl = control,
                      method = "rf", 
                      tuneGrid = expand.grid(mtry = 15), verbose = T)

```
##Svm
```{r}

# RADIAL SVM on complete training set

control <- trainControl(method = "cv", number = 5, verboseIter = T, savePredictions = T)

set.seed(100)
svm_radial <- train(context~., data = training_set %>% select(context, numeric_features), trControl = control, method = "svmRadial", 
                         tuneGrid  = expand.grid(C =c(0.75,1,1.5,2,5,10,15,20,30,40), sigma = seq(0.01,0.2, by = 0.01)))

#The best svm only achieves 87.5 % of accuracy. Nevertheless, it might increase if only the most important features for the random forest are used to train the algorithm.


set.seed(100)
svm_radial_imp <- train(context~., data = training_set %>% select(context, imp_features_rf), trControl = control, method = "svmRadial", 
                         tuneGrid  = expand.grid(C =c(0.25, 0.5,0.75,1,1.5,2,5,10,15), sigma = seq(0.01,0.2, by = 0.01)))

#By including only the most relevant features for the random forest the accuracy has risen to 90.7 %. It is the same value that the random forest. 

```
#Final model
A random forest was the most optimal model with an accuracy close to 91 % using 5-fold cross-validation. Therefore, we will use this model in the downstream analysis. 
##Confusion matrix
```{r}

saveRDS(rf_optimized, "objects_classification/classifiers/density_classifier.rds")

#Confusion matrix

conf_optimal_rf <- table(rf_optimized$pred$obs, rf_optimized$pred$pred) %>% as.data.frame() %>% arrange(Var1, Var2) %>% group_by(Var1) %>%                                        mutate(proportion_cells = Freq/sum(Freq), Var2 = factor(Var2, levels = c("Isolated", "Crowded")))
                         

#In the confusion matrix it is nicer if the labels are well segmented and wrong segmented
    
load("~/Desktop/Sergi_master_thesis/themes/confusion_matrix_theme.RData")


confusion_matrix_optimal_rf <- ggplot(conf_optimal_rf, aes(x=Var1, y= Var2, fill = proportion_cells))+
                               geom_tile()+
                               scale_x_discrete(expand = c(0,0))+
                               scale_y_discrete(expand = c(0,0))+
                               scale_fill_gradient(low = "white", high = "#4885ed")+
                               confusion_matrix_theme()+
                               theme(
                                 legend.position = "none")+
                               xlab("user-defined group")+
                               ylab("predicted group")+
                               geom_label(data = conf_optimal_rf %>% filter(proportion_cells>0.05), 
                                          aes(x = Var1, y = Var2, label = round(proportion_cells, 2)), size = 6,
                                              label.size = 0.5)
       

ggsave(confusion_matrix_optimal_rf, filename = "objects_classification/plots/confusion_matrix.pdf")

```

#Supp Figures thesis

In the supplementaries of the thesis I will add a plot for every classification algorithm, which will include the confusion matrix and a table of the training set composition. 

I would like to make the plots quite small since they're supplementary material, that's why I'll make the labels bigger.


```{r}


init_numb_traning <- readRDS("objects/numbers_table.rds") %>% 
                        select(group, number_cells) 


#Labelling table


colnames(init_numb_traning) <- c("Group", "Number cells")

rownames(init_numb_traning) <- NULL


supp_figure_arrnged <- grid.arrange(arrangeGrob(confusion_matrix_optimal_rf + 
                                                  theme(legend.position = "bottom") +
                                                guides(fill = guide_colourbar(
                                                                       title.hjust = 0.5,
                                                                      barwidth = unit(5, "cm"),
                                                                      title.vjust = 0.9,
                                                                      ))+
                                                  labs(fill = "Proportion of cells")),
                                    arrangeGrob(tableGrob(init_numb_traning, rows = NULL, 
                                                   theme = ttheme_default(base_size = 15))), 
                                    ncol = 2, widths = c(1.25, 1))


ggsave(supp_figure_arrnged, filename = "plots_thesis/supp_figure8.pdf", height = 6, width = 13)

```


